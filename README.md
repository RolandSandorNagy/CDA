# 🧾 Collateral Description Agent

This project implements an automated collateral description pipeline. It takes a folder of images for an asset and generates a structured markdown appraisal report based on:
- Image captions (via BLIP)
- OCR-extracted text (via Tesseract)
- Rule-based domain classification
- Structured markdown prompts
- Final report from a Qwen-32B endpoint

---

## 🔧 Installation

### Dependencies
Install Python dependencies:

```bash
pip install -r requirements.txt
```

Install Tesseract OCR manually:
- Windows: https://github.com/tesseract-ocr/tessdoc#binaries
- Linux: `sudo apt install tesseract-ocr`

---

## 🚀 Usage

1. Put asset folders in `./datasets/ASSET_ID/`
2. Run the script:

```bash
python app.py
```

This will generate:
- `instructblip_ocr_results.json` – captions + OCR
- `qwen_prompt_<assetID>.md` – markdown prompt for Qwen
- `qwen_output_<assetID>.md` – final report

---

## 🌐 API Details

The report is generated by querying a **Qwen-32B-AWQ** chat endpoint hosted at ELTE.

You can modify the API URL and key at the bottom of `app.py`:
```python
API_URL = "http://mobydick.elte-dh.hu:24642/v1/chat/completions"
API_KEY = "..."
```

---

## 📁 Folder Structure

```
project/
├── app.py
├── requirements.txt
├── README.md
├── datasets/
│   └── 157515_v2/
│       ├── image1.jpg
│       ├── ...
│       └── qwen_output_157515_v2.md
```

---

## 🛠️ Notes

- You can override auto-generated captions using `manual_descriptions` in the script.
- The BLIP model is small enough to run on most laptops.
- InstructBLIP was too large for typical CPU environments.

---

## 📃 License

Open-source educational project for ELTE GenAI course. Do not reuse the dataset or API without permission.