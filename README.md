# ğŸ§¾ Collateral Description Agent

This project implements an automated collateral description pipeline. It takes a folder of images for an asset and generates a structured markdown appraisal report based on:
- Image captions (via BLIP)
- OCR-extracted text (via Tesseract)
- Rule-based domain classification
- Structured markdown prompts
- Final report from a Qwen-32B endpoint

---

## ğŸ”§ Installation

### Dependencies
Install Python dependencies:

```bash
pip install -r requirements.txt
```

Install Tesseract OCR manually:
- Windows: https://github.com/tesseract-ocr/tessdoc#binaries
- Linux: `sudo apt install tesseract-ocr`

---

## ğŸš€ Usage

1. Put asset folders in `./datasets/ASSET_ID/`
2. Run the script:

```bash
python app.py
```

This will generate:
- `instructblip_ocr_results.json` â€“ captions + OCR
- `qwen_prompt_<assetID>.md` â€“ markdown prompt for Qwen
- `qwen_output_<assetID>.md` â€“ final report

---

## ğŸŒ API Details

The report is generated by querying a **Qwen-32B-AWQ** chat endpoint hosted at ELTE.

You can modify the API URL and key at the bottom of `app.py`:
```python
API_URL = "http://mobydick.elte-dh.hu:24642/v1/chat/completions"
API_KEY = "..."
```

---

## ğŸ“ Folder Structure

```
project/
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ README.md
â”œâ”€â”€ datasets/
â”‚   â””â”€â”€ 157515_v2/
â”‚       â”œâ”€â”€ image1.jpg
â”‚       â”œâ”€â”€ ...
â”‚       â””â”€â”€ qwen_output_157515_v2.md
```

---

## ğŸ› ï¸ Notes

- You can override auto-generated captions using `manual_descriptions` in the script.
- The BLIP model is small enough to run on most laptops.
- InstructBLIP was too large for typical CPU environments.

---

## ğŸ“ƒ License

Open-source educational project for ELTE GenAI course. Do not reuse the dataset or API without permission.